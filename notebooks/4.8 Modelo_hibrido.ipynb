{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481e06f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üéØ OPTIMIZACI√ìN CORREGIDA - SIN DATA LEAKAGE\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Split temporal correcto:\n",
      "   Train: 6221 filas (2008-2022)\n",
      "   Test:  1358 filas (2023-2024)\n",
      "\n",
      "‚ö†Ô∏è  Test set NUNCA se usa en entrenamiento u optimizaci√≥n\n",
      "\n",
      "üìä Distribuci√≥n CORRECTA (solo train):\n",
      "   EARLY:  1592 filas | A√±os 2008-2022\n",
      "     MID:  2226 filas | A√±os 2008-2022\n",
      "    LATE:  2403 filas | A√±os 2008-2022\n",
      "\n",
      "================================================================================\n",
      "üöÄ INICIANDO OPTIMIZACI√ìN (SOLO con 2008-2022)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "üîç OPTIMIZANDO FASE: EARLY\n",
      "================================================================================\n",
      "Datos: 1592 filas (2008-2022)\n",
      "‚è≥ Entrenando 40 √ó 5 = 200 modelos...\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "\n",
      "‚úÖ MEJOR CONFIGURACI√ìN:\n",
      "   Spearman CV:  0.8685\n",
      "   Spearman Train: 0.8617\n",
      "   Overfitting: -0.0068\n",
      "\n",
      "   Hiperpar√°metros:\n",
      "      colsample_bytree    : 0.8\n",
      "      learning_rate       : 0.03\n",
      "      max_depth           : 2\n",
      "      n_estimators        : 100\n",
      "      reg_alpha           : 2.0\n",
      "      reg_lambda          : 1.0\n",
      "      subsample           : 0.8\n",
      "\n",
      "================================================================================\n",
      "üîç OPTIMIZANDO FASE: MID\n",
      "================================================================================\n",
      "Datos: 2226 filas (2008-2022)\n",
      "‚è≥ Entrenando 40 √ó 5 = 200 modelos...\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "\n",
      "‚úÖ MEJOR CONFIGURACI√ìN:\n",
      "   Spearman CV:  0.9586\n",
      "   Spearman Train: 0.9940\n",
      "   Overfitting: 0.0354\n",
      "\n",
      "   Hiperpar√°metros:\n",
      "      colsample_bytree    : 0.8\n",
      "      learning_rate       : 0.05\n",
      "      max_depth           : 5\n",
      "      n_estimators        : 200\n",
      "      reg_alpha           : 0\n",
      "      reg_lambda          : 1.0\n",
      "      subsample           : 0.9\n",
      "\n",
      "================================================================================\n",
      "üîç OPTIMIZANDO FASE: LATE\n",
      "================================================================================\n",
      "Datos: 2403 filas (2008-2022)\n",
      "‚è≥ Entrenando 40 √ó 5 = 200 modelos...\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "\n",
      "‚úÖ MEJOR CONFIGURACI√ìN:\n",
      "   Spearman CV:  0.9890\n",
      "   Spearman Train: 0.9964\n",
      "   Overfitting: 0.0075\n",
      "\n",
      "   Hiperpar√°metros:\n",
      "      colsample_bytree    : 1.0\n",
      "      learning_rate       : 0.1\n",
      "      max_depth           : 5\n",
      "      n_estimators        : 150\n",
      "      reg_alpha           : 0\n",
      "      reg_lambda          : 1.0\n",
      "      subsample           : 0.9\n",
      "\n",
      "================================================================================\n",
      "üèóÔ∏è  ENTRENANDO MODELOS FINALES (2008-2022)\n",
      "================================================================================\n",
      "\n",
      "üîß Entrenando modelo final EARLY...\n",
      "   ‚úÖ Modelo EARLY entrenado\n",
      "\n",
      "üîß Entrenando modelo final MID...\n",
      "   ‚úÖ Modelo MID entrenado\n",
      "\n",
      "üîß Entrenando modelo final LATE...\n",
      "   ‚úÖ Modelo LATE entrenado\n",
      "\n",
      "================================================================================\n",
      "üìä EVALUACI√ìN EN TEST SET (2023-2024) - NUNCA VISTO\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "üéØ M√âTRICAS FINALES (SIN DATA LEAKAGE)\n",
      "================================================================================\n",
      "\n",
      "   Spearman:  0.9248  ‚≠ê\n",
      "   MAE:       0.0099  (0.99%)\n",
      "   RMSE:      0.0172\n",
      "   R¬≤:        0.9025  (90.3%)\n",
      "\n",
      "================================================================================\n",
      "üìà COMPARACI√ìN CON BASELINE 4C\n",
      "================================================================================\n",
      "\n",
      "   Baseline 4C:     0.8955\n",
      "   Este modelo:     0.9248\n",
      "   Mejora REAL:     +2.93%\n",
      "\n",
      "   ‚úÖ MEJORA SIGNIFICATIVA!\n",
      "\n",
      "================================================================================\n",
      "üìä FEATURE IMPORTANCE (MODELO LATE)\n",
      "================================================================================\n",
      "\n",
      "Features ordenadas por importancia:\n",
      "\n",
      "   1. pct_puntos_actual              0.9298 (93.0%)\n",
      "   2. diff_con_lider_normalizada     0.0263 (2.6%)\n",
      "   3. progreso_temporada             0.0248 (2.5%)\n",
      "   4. team_avg_pos_3y                0.0046 (0.5%)\n",
      "   5. driver_quality_3y              0.0045 (0.5%)\n",
      "   6. pct_linear_points              0.0036 (0.4%)\n",
      "   7. tendencia_ultimas_3            0.0035 (0.4%)\n",
      "   8. team_trend                     0.0030 (0.3%)\n",
      "\n",
      "================================================================================\n",
      "üíæ GUARDANDO MODELOS\n",
      "================================================================================\n",
      "‚úÖ Guardado: ../models/xgboost_early_v5.pkl\n",
      "‚úÖ Guardado: ../models/xgboost_mid_v5.pkl\n",
      "‚úÖ Guardado: ../models/xgboost_late_v5.pkl\n",
      "‚úÖ Guardado: ../models/config_hibrido_v5.pkl\n",
      "\n",
      "================================================================================\n",
      "‚úÖ OPTIMIZACI√ìN COMPLETADA (SIN DATA LEAKAGE)\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# MODELO H√çBRIDO FINAL\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "from scipy.stats import spearmanr\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==================== CONFIGURACI√ìN ====================\n",
    "\n",
    "INPUT_FILE = '../data/processed/f1_features_complete.csv'\n",
    "OUTPUT_DIR = '../models'\n",
    "\n",
    "feature_cols = [\n",
    "    'pct_puntos_actual',\n",
    "    'pct_linear_points',\n",
    "    'tendencia_ultimas_3',\n",
    "    'diff_con_lider_normalizada',\n",
    "    'progreso_temporada',\n",
    "    'driver_quality_3y',\n",
    "    'team_avg_pos_3y',\n",
    "    'team_trend'\n",
    "]\n",
    "target_col = 'pct_puntos_final'\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üéØ OPTIMIZACI√ìN CORREGIDA - SIN DATA LEAKAGE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ==================== CARGAR Y SPLIT TEMPORAL ====================\n",
    "\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "df = df.sort_values(['year', 'round']).reset_index(drop=True)\n",
    "\n",
    "# üö® CR√çTICO: SPLIT TEMPORAL PRIMERO\n",
    "df_train = df[df['year'] <= 2022].copy()\n",
    "df_test = df[df['year'] >= 2023].copy()\n",
    "\n",
    "print(f\"\\n‚úÖ Split temporal correcto:\")\n",
    "print(f\"   Train: {len(df_train)} filas (2008-2022)\")\n",
    "print(f\"   Test:  {len(df_test)} filas (2023-2024)\")\n",
    "print(f\"\\n‚ö†Ô∏è  Test set NUNCA se usa en entrenamiento u optimizaci√≥n\")\n",
    "\n",
    "# ==================== CREAR FASES SOLO CON TRAIN ====================\n",
    "\n",
    "fases_data_train = {\n",
    "    'EARLY': df_train[df_train['round'] <= 5],\n",
    "    'MID':   df_train[(df_train['round'] > 5) & (df_train['round'] <= 12)],\n",
    "    'LATE':  df_train[df_train['round'] > 12]\n",
    "}\n",
    "\n",
    "print(f\"\\nüìä Distribuci√≥n CORRECTA (solo train):\")\n",
    "for fase_name, df_fase in fases_data_train.items():\n",
    "    print(f\"   {fase_name:>5}: {len(df_fase):>5} filas | \"\n",
    "          f\"A√±os {df_fase['year'].min()}-{df_fase['year'].max()}\")\n",
    "\n",
    "# ==================== GRIDS DE HIPERPAR√ÅMETROS ====================\n",
    "\n",
    "param_grid_early = {\n",
    "    'n_estimators': [100, 150, 200, 300],\n",
    "    'max_depth': [2, 3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.08],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8],\n",
    "    'reg_alpha': [0.1, 0.5, 1.0, 2.0],\n",
    "    'reg_lambda': [1.0, 3.0, 5.0, 10.0]\n",
    "}\n",
    "\n",
    "param_grid_mid = {\n",
    "    'n_estimators': [100, 150, 200, 250],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'learning_rate': [0.05, 0.08, 0.1, 0.12],\n",
    "    'subsample': [0.8, 0.9, 0.95],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1.0],\n",
    "    'reg_lambda': [0.1, 1.0, 3.0, 5.0]\n",
    "}\n",
    "\n",
    "param_grid_late = {\n",
    "    'n_estimators': [100, 150, 200, 250],\n",
    "    'max_depth': [5, 6, 7, 8],\n",
    "    'learning_rate': [0.08, 0.1, 0.12, 0.15],\n",
    "    'subsample': [0.9, 0.95, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [0, 0.1, 1.0, 3.0]\n",
    "}\n",
    "\n",
    "grids = {\n",
    "    'EARLY': param_grid_early,\n",
    "    'MID': param_grid_mid,\n",
    "    'LATE': param_grid_late\n",
    "}\n",
    "\n",
    "# ==================== OPTIMIZACI√ìN ====================\n",
    "\n",
    "def spearman_scorer(y_true, y_pred):\n",
    "    corr, _ = spearmanr(y_true, y_pred)\n",
    "    return corr\n",
    "\n",
    "spearman_score = make_scorer(spearman_scorer, greater_is_better=True)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üöÄ INICIANDO OPTIMIZACI√ìN (SOLO con 2008-2022)\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "resultados_optimizacion = {}\n",
    "\n",
    "for fase_name, df_fase in fases_data_train.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üîç OPTIMIZANDO FASE: {fase_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Datos: {len(df_fase)} filas (2008-2022)\")\n",
    "    \n",
    "    X_fase = df_fase[feature_cols]\n",
    "    y_fase = df_fase[target_col]\n",
    "    \n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=xgb_model,\n",
    "        param_distributions=grids[fase_name],\n",
    "        n_iter=40,\n",
    "        cv=tscv,\n",
    "        scoring=spearman_score,\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "        return_train_score=True\n",
    "    )\n",
    "    \n",
    "    print(f\"‚è≥ Entrenando 40 √ó 5 = 200 modelos...\")\n",
    "    search.fit(X_fase, y_fase)\n",
    "    \n",
    "    best_params = search.best_params_\n",
    "    best_spearman = search.best_score_\n",
    "    \n",
    "    cv_results = search.cv_results_\n",
    "    best_idx = search.best_index_\n",
    "    train_score = cv_results['mean_train_score'][best_idx]\n",
    "    test_score = cv_results['mean_test_score'][best_idx]\n",
    "    overfitting = train_score - test_score\n",
    "    \n",
    "    resultados_optimizacion[fase_name] = {\n",
    "        'params': best_params,\n",
    "        'spearman_cv': best_spearman,\n",
    "        'spearman_train': train_score,\n",
    "        'overfitting': overfitting,\n",
    "        'modelo': search.best_estimator_\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n‚úÖ MEJOR CONFIGURACI√ìN:\")\n",
    "    print(f\"   Spearman CV:  {best_spearman:.4f}\")\n",
    "    print(f\"   Spearman Train: {train_score:.4f}\")\n",
    "    print(f\"   Overfitting: {overfitting:.4f}\")\n",
    "    print(f\"\\n   Hiperpar√°metros:\")\n",
    "    for param, value in sorted(best_params.items()):\n",
    "        print(f\"      {param:20}: {value}\")\n",
    "\n",
    "# ==================== ENTRENAR MODELOS FINALES ====================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üèóÔ∏è  ENTRENANDO MODELOS FINALES (2008-2022)\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "modelos_finales = {}\n",
    "\n",
    "for fase_name, df_fase in fases_data_train.items():\n",
    "    print(f\"\\nüîß Entrenando modelo final {fase_name}...\")\n",
    "    \n",
    "    X_fase = df_fase[feature_cols]\n",
    "    y_fase = df_fase[target_col]\n",
    "    \n",
    "    best_params = resultados_optimizacion[fase_name]['params']\n",
    "    \n",
    "    modelo_final = xgb.XGBRegressor(\n",
    "        **best_params,\n",
    "        objective='reg:squarederror',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    modelo_final.fit(X_fase, y_fase)\n",
    "    \n",
    "    modelos_finales[fase_name] = modelo_final\n",
    "    print(f\"   ‚úÖ Modelo {fase_name} entrenado\")\n",
    "\n",
    "# ==================== EVALUACI√ìN EN TEST ====================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üìä EVALUACI√ìN EN TEST SET (2023-2024) - NUNCA VISTO\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "def predecir_hibrido(df_test_input, modelos):\n",
    "    predicciones = []\n",
    "    \n",
    "    for idx, row in df_test_input.iterrows():\n",
    "        round_num = row['round']\n",
    "        \n",
    "        if round_num <= 5:\n",
    "            modelo = modelos['EARLY']\n",
    "        elif round_num <= 12:\n",
    "            modelo = modelos['MID']\n",
    "        else:\n",
    "            modelo = modelos['LATE']\n",
    "        \n",
    "        X_row = row[feature_cols].values.reshape(1, -1)\n",
    "        pred = modelo.predict(X_row)[0]\n",
    "        predicciones.append(pred)\n",
    "    \n",
    "    return np.array(predicciones)\n",
    "\n",
    "y_test = df_test[target_col]\n",
    "y_test_pred = predecir_hibrido(df_test, modelos_finales)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "test_spearman, _ = spearmanr(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üéØ M√âTRICAS FINALES (SIN DATA LEAKAGE)\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\n   Spearman:  {test_spearman:.4f}  ‚≠ê\")\n",
    "print(f\"   MAE:       {test_mae:.4f}  ({test_mae*100:.2f}%)\")\n",
    "print(f\"   RMSE:      {test_rmse:.4f}\")\n",
    "print(f\"   R¬≤:        {test_r2:.4f}  ({test_r2*100:.1f}%)\")\n",
    "\n",
    "baseline_spearman = 0.8955\n",
    "mejora = (test_spearman - baseline_spearman) * 100\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üìà COMPARACI√ìN CON BASELINE 4C\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\n   Baseline 4C:     {baseline_spearman:.4f}\")\n",
    "print(f\"   Este modelo:     {test_spearman:.4f}\")\n",
    "print(f\"   Mejora REAL:     {mejora:+.2f}%\")\n",
    "\n",
    "if test_spearman > baseline_spearman:\n",
    "    if mejora > 1.0:\n",
    "        print(f\"\\n   ‚úÖ MEJORA SIGNIFICATIVA!\")\n",
    "    else:\n",
    "        print(f\"\\n   ‚ö†Ô∏è  Mejora marginal\")\n",
    "else:\n",
    "    print(f\"\\n   ‚ùå No hay mejora\")\n",
    "\n",
    "# ==================== FEATURE IMPORTANCE ====================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üìä FEATURE IMPORTANCE (MODELO LATE)\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "importances = modelos_finales['LATE'].feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"\\nFeatures ordenadas por importancia:\\n\")\n",
    "for i, idx in enumerate(indices, 1):\n",
    "    feat = feature_cols[idx]\n",
    "    imp = importances[idx]\n",
    "    print(f\"   {i}. {feat:30} {imp:.4f} ({imp*100:.1f}%)\")\n",
    "\n",
    "# ==================== GUARDAR ====================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üíæ GUARDANDO MODELOS\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for fase_name, modelo in modelos_finales.items():\n",
    "    filename = f'{OUTPUT_DIR}/xgboost_{fase_name.lower()}_v5.pkl'\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'modelo': modelo,\n",
    "            'features': feature_cols,\n",
    "            'params': resultados_optimizacion[fase_name]['params'],\n",
    "            'metricas': {\n",
    "                'spearman_cv': resultados_optimizacion[fase_name]['spearman_cv'],\n",
    "                'overfitting': resultados_optimizacion[fase_name]['overfitting']\n",
    "            }\n",
    "        }, f)\n",
    "    print(f\"‚úÖ Guardado: {filename}\")\n",
    "\n",
    "config_hibrido = {\n",
    "    'modelos': {\n",
    "        'early': {\n",
    "            'params': resultados_optimizacion['EARLY']['params'],\n",
    "            'features': feature_cols,\n",
    "            'metricas': {\n",
    "                'spearman': resultados_optimizacion['EARLY']['spearman_cv'],\n",
    "                'overfitting': resultados_optimizacion['EARLY']['overfitting']\n",
    "            }\n",
    "        },\n",
    "        'mid': {\n",
    "            'params': resultados_optimizacion['MID']['params'],\n",
    "            'features': feature_cols,\n",
    "            'metricas': {\n",
    "                'spearman': resultados_optimizacion['MID']['spearman_cv'],\n",
    "                'overfitting': resultados_optimizacion['MID']['overfitting']\n",
    "            }\n",
    "        },\n",
    "        'late': {\n",
    "            'params': resultados_optimizacion['LATE']['params'],\n",
    "            'features': feature_cols,\n",
    "            'metricas': {\n",
    "                'spearman': resultados_optimizacion['LATE']['spearman_cv'],\n",
    "                'overfitting': resultados_optimizacion['LATE']['overfitting']\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'metricas_hibrido': {\n",
    "        'spearman': test_spearman,\n",
    "        'mae': test_mae,\n",
    "        'rmse': test_rmse,\n",
    "        'r2': test_r2\n",
    "    },\n",
    "    'comparacion_baseline': {\n",
    "        'baseline_4c': baseline_spearman,\n",
    "        'modelo_optimizado': test_spearman,\n",
    "        'mejora_porcentual': mejora\n",
    "    },\n",
    "    'features_utilizadas': feature_cols,\n",
    "    'features_eliminadas': ['posicion_media'],\n",
    "    'train_years': '2008-2022',\n",
    "    'test_years': '2023-2024',\n",
    "    'fecha_entrenamiento': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "config_file = f'{OUTPUT_DIR}/config_hibrido_v5.pkl'\n",
    "with open(config_file, 'wb') as f:\n",
    "    pickle.dump(config_hibrido, f)\n",
    "\n",
    "print(f\"‚úÖ Guardado: {config_file}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"‚úÖ OPTIMIZACI√ìN COMPLETADA (SIN DATA LEAKAGE)\")\n",
    "print(f\"{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0b7f74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
